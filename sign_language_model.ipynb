{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyME3hm/Avkj1metWmYxJBOk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luckystarlet/whatapp-forkitonyi/blob/main/sign_language_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "0xj7iPgRsBMM",
        "outputId": "e58c4849-af42-4e84-f6ea-31138f9bdbed"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-20-b9c05677d292>, line 18)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-b9c05677d292>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    for sign_label in os.listdir(csv_path):  # Corrected variable name\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Load the CSV file\n",
        "mnist_train_small = pd.read_csv(\"/content/sample_data/mnist_train_small.csv\")\n",
        "# Path to the dataset directory containing sign language images\n",
        "mnist_train_small_path = \"/content/sample_data/mnist_train_small\"\n",
        "\n",
        "# Preprocess images\n",
        "def preprocess_images(csv_path, img_size=(224, 224)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    # Preprocess images\n",
        "images, labels = preprocess_images(mnist_train_small_path)\n",
        "    # Iterate through each folder (each sign) in the dataset\n",
        "    for sign_label in os.listdir(csv_path):  # Corrected variable name\n",
        "        sign_path = os.path.join(mnist_train_small.cvs, sign_label)\n",
        "        if os.path.isdir(sign_path):\n",
        "            label = int(sign_label)  # Convert folder name to label (assuming folder names are numeric)\n",
        "            for image_file in os.listdir(sign_path):\n",
        "                image_path = os.path.join(sign_path, image_file)\n",
        "                # Try to read the image\n",
        "                try:\n",
        "                    # Read image and resize\n",
        "                    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "                    image = cv2.resize(image, img_size)\n",
        "                    # Normalize pixel values\n",
        "                    image = image / 255.0\n",
        "                    images.append(image)\n",
        "                    labels.append(label)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing image {image_path}: {e}\")\n",
        "                    # Remove the corrupted image from the dataset\n",
        "                    os.remove(image_path)\n",
        "\n",
        "    # Convert lists to NumPy arrays\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "\n",
        "    return (images, labels)\n",
        "\n",
        "# Path to the dataset directory containing sign language images\n",
        "mnist_train_small.cvs = \"/content/sample_data/mnist_train_small.csv\"\n",
        "\n",
        "# Preprocess images\n",
        "images, labels = preprocess_images(mnist_train_small.cvs)\n",
        "\n",
        "# Split the dataset into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Print shapes of the datasets\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
        "print(\"Test set shape:\", X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "source": [
        "# Load the CSV file\n",
        "mnist_train_small = pd.read_csv(\"/content/sample_data/mnist_train_small.csv\")\n",
        "\n",
        "# Preprocess images\n",
        "def preprocess_images(csv_data, img_size=(224, 224)):\n",
        "    # ... (same as before)\n",
        "\n",
        "# Preprocess images\n",
        "images, labels = preprocess_images(mnist_train_small, img_size=(224, 224))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "pccVxI-9Cx6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Load the CSV file\n",
        "mnist_train_small = pd.read_csv(\"/content/sample_data/mnist_train_small.csv\")\n",
        "\n",
        "# Preprocess images\n",
        "def preprocess_images(csv_data, img_size=(224, 224)):\n",
        "    # ... (same as before)\n",
        "\n",
        "# Preprocess images\n",
        "images, labels = preprocess_images(mnist_train_small, img_size=(224, 224))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ZNYV3eBrCywT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Load the CSV file\n",
        "mnist_train_small = pd.read_csv(\"/content/sample_data/mnist_train_small.csv\")\n",
        "\n",
        "# Preprocess images\n",
        "def preprocess_images(csv_data, img_size=(224, 224)):\n",
        "    # ... (same as before)\n",
        "\n",
        "# Preprocess images\n",
        "images, labels = preprocess_images(mnist_train_small, img_size=(224, 224))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "AaifHgRWCzPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Load the CSV file\n",
        "mnist_train_small = pd.read_csv(\"/content/sample_data/mnist_train_small.csv\")\n",
        "\n",
        "# Preprocess images\n",
        "def preprocess_images(csv_data, img_size=(224, 224)):\n",
        "    # ... (same as before)\n",
        "\n",
        "# Preprocess images\n",
        "images, labels = preprocess_images(mnist_train_small, img_size=(224, 224))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "NoplMTGUCzlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Load the CSV file\n",
        "mnist_train_small = pd.read_csv(\"/content/sample_data/mnist_train_small.csv\")\n",
        "\n",
        "# Preprocess images\n",
        "def preprocess_images(csv_data, img_size=(224, 224)):\n",
        "    # ... (same as before)\n",
        "\n",
        "# Preprocess images\n",
        "images, labels = preprocess_images(mnist_train_small, img_size=(224, 224))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "zjAOXiBsCz_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Load the CSV file\n",
        "mnist_train_small = pd.read_csv(\"/content/sample_data/mnist_train_small.csv\")\n",
        "\n",
        "# Preprocess images\n",
        "def preprocess_images(csv_data, img_size=(224, 224)):\n",
        "    # ... (same as before)\n",
        "\n",
        "# Preprocess images\n",
        "images, labels = preprocess_images(mnist_train_small, img_size=(224, 224))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "2W46igLgC0SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Load the CSV file\n",
        "mnist_train_small = pd.read_csv(\"/content/sample_data/mnist_train_small.csv\")\n",
        "\n",
        "# Preprocess images\n",
        "def preprocess_images(csv_data, img_size=(224, 224)):\n",
        "    # ... (same as before)\n",
        "\n",
        "# Preprocess images\n",
        "images, labels = preprocess_images(mnist_train_small, img_size=(224, 224))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "lNXux5VeC0jk",
        "outputId": "7c945003-940f-430f-c347-31682d5d5c24"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after function definition on line 5 (<ipython-input-19-9cbd79413f19>, line 9)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-9cbd79413f19>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    images, labels = preprocess_images(mnist_train_small, img_size=(224, 224))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 5\n"
          ]
        }
      ]
    }
  ]
}